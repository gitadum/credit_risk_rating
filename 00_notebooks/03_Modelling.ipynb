{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initialisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importations\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from preprocessing import preprocessor as prep\n",
    "from preprocessing import preprocessor_no_scaler as prep_no_scl\n",
    "from styles import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Initialisation\n",
    "train = pd.read_csv('../02_data/application_train.csv')\n",
    "test = pd.read_csv('../02_data/application_test.csv')\n",
    "\n",
    "id_error_msg = lambda x: '`SK_ID_CURR` is not unic for {} set!'.format(x)\n",
    "assert len(train.SK_ID_CURR.unique()) == train.shape[0], id_error_msg('train')\n",
    "assert len(test.SK_ID_CURR.unique()) == test.shape[0], id_error_msg('test')\n",
    "train.set_index('SK_ID_CURR', inplace=True)\n",
    "test.set_index('SK_ID_CURR', inplace=True)\n",
    "\n",
    "print('Training set dimensions :', train.shape)\n",
    "\n",
    "cls_size = train.TARGET.value_counts()\n",
    "cls_freq = train.TARGET.value_counts(normalize=True)\n",
    "print(pd.DataFrame({'size': cls_size,\n",
    "                    'freq': cls_freq.apply(lambda x: '%.3f' % x)}))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set dimensions : (307511, 121)\n",
      "     size   freq\n",
      "0  282686  0.919\n",
      "1   24825  0.081\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_sample = train[::10]\n",
    "print('Sampled training set dimensions :', train_sample.shape)\n",
    "cls_size = train.TARGET.value_counts()\n",
    "cls_freq = train.TARGET.value_counts(normalize=True)\n",
    "print(pd.DataFrame({'size': cls_size,\n",
    "                    'freq': cls_freq.apply(lambda x: '%.3f' % x)}))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sampled training set dimensions : (30752, 121)\n",
      "     size   freq\n",
      "0  282686  0.919\n",
      "1   24825  0.081\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "On échantillonne le dataset en prenant 10% des points de données"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X, y = train.iloc[:, 1:], train.iloc[:, 0].values.reshape(-1,1)\n",
    "Xs, ys = train_sample.iloc[:, 1:], train_sample.iloc[:, 0].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=.2)\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train: (24601, 120)\n",
      "y_train: (24601, 1)\n",
      "X_test: (6151, 120)\n",
      "y_test: (6151, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rééquilibrage de classes - SMOTE/Tomek"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il y a ~8% de cas de défaut dans le jeu d'entraînement contre 92% de cas sans défaut. Le déséquilibre des classes pose problème dans le cadre de la prédiction de la classe minoritaire par un algorithme de ml.\n",
    "\n",
    "Il faut rééquilibrer les classes du jeu d'entraînement avant de sélectionner le meilleur modèle de ml "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impact de SMOTE Tomek sur l'entraînement d'un modèle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "sgd = Pipeline([('p', prep), ('m', SGDClassifier())])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scoring = ['precision_macro','recall_macro'] #, 'accuracy']\n",
    "sgd_scor = cross_validate(sgd, X_train, y_train, scoring=scoring, cv=cv)\n",
    "print('Model 1\\n' + line_decor)\n",
    "#print('accuracy scores:', sgd_scor['test_accuracy'])\n",
    "print('precision scores:', sgd_scor['test_precision_macro'])\n",
    "print('recall scores:', sgd_scor['test_recall_macro'])\n",
    "#print('Mean Accuracy: %.4f' % np.mean(sgd_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.nanmean(sgd_scor['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.nanmean(sgd_scor['test_recall_macro']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "precision scores: [0.46006909 0.4601626  0.46006098        nan        nan]\n",
      "recall scores: [0.5 0.5 0.5 nan nan]\n",
      "Mean Precision: 0.4601\n",
      "Mean Recall: 0.5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validation croisée sans SMOTE Tomek : 8.7s avec un échantillon divisé par 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "resampler = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "sgd_imb = Pipeline([('p', prep), ('r', resampler), ('m', SGDClassifier())])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scoring = ['precision_macro','recall_macro'] #, 'accuracy']\n",
    "sgd_imb_scor = cross_validate(sgd_imb, X_train, y_train, scoring=scoring, cv=5)\n",
    "print('Model 1 - with imbalance handling\\n' + line_decor)\n",
    "#print('accuracy scores:', sgd_imb_scor['test_accuracy'])\n",
    "print('precision scores:', sgd_imb_scor['test_precision_macro'])\n",
    "print('recall scores:', sgd_imb_scor['test_recall_macro'])\n",
    "#print('Mean Accuracy: %.4f' % np.mean(sgd_imb_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.nanmean(sgd_imb_scor['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.nanmean(sgd_imb_scor['test_recall_macro']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1 - with imbalance handling\n",
      "--------\n",
      "precision scores: [0.56034957 0.54690774        nan        nan 0.5494052 ]\n",
      "recall scores: [0.6731755  0.64322447        nan        nan 0.66568275]\n",
      "Mean Precision: 0.5522\n",
      "Mean Recall: 0.6607\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validation croisée avec SMOTE Tomek (stratégie majoritaire) : 207.6s avec un échantillon divisé par 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "smote_unsmote_ratio = 207.6 / 8.7\n",
    "print('{:.2f}'.format(smote_unsmote_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.86\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le SMOTE Tomek multiplie par 24 le temps d'exécution du modèle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Essai d'une validation croisée sans SMOTE Tomek avec tous les points du jeu d'entraînement"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train: (246008, 120)\n",
      "y_train: (246008, 1)\n",
      "X_test: (61503, 120)\n",
      "y_test: (61503, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "sgd = Pipeline([('p', prep), ('m', SGDClassifier())])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scoring = ['precision_macro','recall_macro'] #, 'accuracy']\n",
    "sgd_scor = cross_validate(sgd, X_train, y_train, scoring=scoring, cv=cv)\n",
    "print('Model 1\\n' + line_decor)\n",
    "#print('accuracy scores:', sgd_scor['test_accuracy'])\n",
    "print('precision scores:', sgd_scor['test_precision_macro'])\n",
    "print('recall scores:', sgd_scor['test_recall_macro'])\n",
    "#print('Mean Accuracy: %.4f' % np.mean(sgd_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.nanmean(sgd_scor['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.nanmean(sgd_scor['test_recall_macro']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "precision scores: [0.45967644 0.45966627 0.45966627 0.45967562 0.45967562]\n",
      "recall scores: [0.5 0.5 0.5 0.5 0.5]\n",
      "Mean Precision: 0.4597\n",
      "Mean Recall: 0.5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validation croisée sans SMOTE Tomek exécutée en 57.9s sur tout le jeu de données"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "unsampled_sampled_ratio = 57.9 / 8.7\n",
    "print('{:.2f}'.format(unsampled_sampled_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6.66\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il faut 7 fois plus de temps pour exécuter la même chose sur 10 fois plus de données (pas parfaitement linéaire donc)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print('{:.2f}'.format(207.6 * unsampled_sampled_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1381.61\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "1381 / 60"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23.016666666666666"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il faudrait 23 minutes rien que pour faire du rééquilibrage avec le jeu de données actuel. Pas souhaitable. \n",
    "\n",
    "**Il faut trouver un moyen de raccourcir le temps d'exécution du rééquilibrage.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle 1 : SGD Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model1 = Pipeline([('p', prep), ('m', SGDClassifier())])\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('Model 1\\n' + line_decor)\n",
    "print('Score: %.4f' % model1.score(X_test, y_test))\n",
    "print(line_decor + '\\nConfusion matrix\\n' + str(conf_mat))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "Score: 0.9190\n",
      "--------\n",
      "Confusion matrix\n",
      "[[56522     0]\n",
      " [ 4981     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56522\n",
      "           1       0.00      0.00      0.00      4981\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.46      0.50      0.48     61503\n",
      "weighted avg       0.84      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle 2 : Random Forest Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model2 = Pipeline([('p', prep_no_scl), ('m', RandomForestClassifier())])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scoring = ['accuracy','precision_macro','recall_macro']\n",
    "scores_model2 = cross_validate(model2, X_train, y_train, scoring=scoring, cv=cv,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "print('Model 2\\n' + 8 * '-')\n",
    "print('Mean Accuracy: %.4f' % np.mean(scores_model2['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.mean(scores_model2['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.mean(scores_model2['test_recall_macro']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model2 = Pipeline([('p', prep_no_scl), ('m', RandomForestClassifier())])\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('Model 2\\n' + 8 * '-')\n",
    "print('Score: %.4f' % model2.score(X_test, y_test))\n",
    "print(8 * '-' + '\\nConfusion matrix\\n' + str(conf_mat))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "Score: 0.9185\n",
      "--------\n",
      "Confusion matrix\n",
      "[[56485     4]\n",
      " [ 5011     3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56489\n",
      "           1       0.43      0.00      0.00      5014\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.67      0.50      0.48     61503\n",
      "weighted avg       0.88      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[56512     5]\n",
      " [ 4979     7]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.get_params()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle 3 : LightGBM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model3 = Pipeline([('p', prep), ('m', LGBMClassifier())])\n",
    "model3.fit(X_train, y_train)\n",
    "print('Score:', model3.score(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score: 0.9192071931450498\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[56447    81]\n",
      " [ 4888    87]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56528\n",
      "           1       0.52      0.02      0.03      4975\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.72      0.51      0.50     61503\n",
      "weighted avg       0.89      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# à faire\n",
    "\n",
    "# smote tomek\n",
    "# random search precision des deux classes (privilégier light_gbm)\n",
    "# \n",
    "# choisir optimisation recall(classe 1)\n",
    "# fonction coût : manque à gagner pour chaque treshold\n",
    "# treshold = + = + precision - recall\n",
    "# precision élevée = on accepte tout le monde\n",
    "# recall élevée = on refuse tout le monde\n",
    "# regarder crer une colonne intérêts (amt credit - good price),\n",
    "# optimiser mon threshold % de ça"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e28ba1b0f05b7395975e75d076f4168a18cd6381404260e3ea0bab694b3a7839"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}