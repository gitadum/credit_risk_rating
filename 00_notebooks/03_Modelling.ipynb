{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initialisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Importations\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler\n",
    "from preprocessing import preprocessor as prep\n",
    "from preprocessing import preprocessor_no_scaler as prep_no_scl\n",
    "from styles import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Initialisation\n",
    "train = pd.read_csv('../02_data/application_train.csv')\n",
    "test = pd.read_csv('../02_data/application_test.csv')\n",
    "\n",
    "id_error_msg = lambda x: '`SK_ID_CURR` is not unic for {} set!'.format(x)\n",
    "assert len(train.SK_ID_CURR.unique()) == train.shape[0], id_error_msg('train')\n",
    "assert len(test.SK_ID_CURR.unique()) == test.shape[0], id_error_msg('test')\n",
    "train.set_index('SK_ID_CURR', inplace=True)\n",
    "test.set_index('SK_ID_CURR', inplace=True)\n",
    "\n",
    "print('Training set dimensions :', train.shape)\n",
    "\n",
    "cls_size = train.TARGET.value_counts()\n",
    "cls_freq = train.TARGET.value_counts(normalize=True)\n",
    "print(pd.DataFrame({'size': cls_size,\n",
    "                    'freq': cls_freq.apply(lambda x: '%.3f' % x)}))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set dimensions : (307511, 121)\n",
      "     size   freq\n",
      "0  282686  0.919\n",
      "1   24825  0.081\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_sample = train[::10]\n",
    "print('Sampled training set dimensions :', train_sample.shape)\n",
    "cls_size = train_sample.TARGET.value_counts()\n",
    "cls_freq = train_sample.TARGET.value_counts(normalize=True)\n",
    "print(pd.DataFrame({'size': cls_size,\n",
    "                    'freq': cls_freq.apply(lambda x: '%.3f' % x)}))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sampled training set dimensions : (30752, 121)\n",
      "    size   freq\n",
      "0  28303  0.920\n",
      "1   2449  0.080\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "On échantillonne le dataset en prenant 10% des points de données"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X, y = train.iloc[:, 1:], train.iloc[:, 0]#.values.reshape(-1,1)\n",
    "Xs, ys = train_sample.iloc[:, 1:], train_sample.iloc[:, 0]#.values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=.2,\n",
    "                                                    random_state=0)\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train: (24601, 120)\n",
      "y_train: (24601,)\n",
      "X_test: (6151, 120)\n",
      "y_test: (6151,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rééquilibrage de classes - SMOTE/Tomek"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il y a ~8% de cas de défaut dans le jeu d'entraînement contre 92% de cas sans défaut. Le déséquilibre des classes pose problème dans le cadre de la prédiction de la classe minoritaire par un algorithme de ml.\n",
    "\n",
    "Il faut rééquilibrer les classes du jeu d'entraînement avant de sélectionner le meilleur modèle de ml "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impact de SMOTE Tomek sur la répartition des classes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "resamplr = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "udsamplr = SMOTEENN(random_state=42)\n",
    "rusamplr = RandomUnderSampler(random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train_trans = prep.fit_transform(X_train)\n",
    "print(X_train_trans.shape)\n",
    "print(X_train_trans)\n",
    "print(y_train.shape)\n",
    "print(y_train.value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24601, 235)\n",
      "[[0.         0.09011628 0.07823375 ... 1.         0.         0.        ]\n",
      " [0.         0.01162791 0.01353611 ... 0.         1.         0.        ]\n",
      " [0.         0.05232558 0.15492746 ... 0.         1.         0.        ]\n",
      " ...\n",
      " [0.         0.14244186 0.1340753  ... 0.         1.         0.        ]\n",
      " [0.1        0.12790698 0.28631022 ... 0.         0.         0.        ]\n",
      " [0.3        0.06395349 0.25047455 ... 0.         1.         0.        ]]\n",
      "(24601,)\n",
      "0    22659\n",
      "1     1942\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "X_train_resampl, y_train_resampl = resamplr.fit_resample(X_train_trans, y_train)\n",
    "print(X_train_resampl.shape)\n",
    "print(y_train_resampl.value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45318, 235)\n",
      "0    22659\n",
      "1    22659\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_train_udsampl, y_train_udsampl = udsamplr.fit_resample(X_train_trans, y_train)\n",
    "print(X_train_udsampl.shape)\n",
    "print(y_train_udsampl.value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(33702, 235)\n",
      "1    22628\n",
      "0    11074\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_train_rusampl, y_train_rusampl = rusamplr.fit_resample(X_train_trans, y_train)\n",
    "print(X_train_rusampl.shape)\n",
    "print(y_train_rusampl.value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3884, 235)\n",
      "0    1942\n",
      "1    1942\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rééquilibrage exécuté en 1min environ pour un jeu d'entraînement divisé par 10."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impact de SMOTE Tomek sur l'entraînement d'un modèle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "sgd = Pipeline([('p', prep), ('m', SGDClassifier())])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scoring = ['precision_macro','recall_macro'] #, 'accuracy']\n",
    "sgd_scor = cross_validate(sgd, X_train, y_train, scoring=scoring, cv=cv)\n",
    "print('Model 1\\n' + line_decor)\n",
    "#print('accuracy scores:', sgd_scor['test_accuracy'])\n",
    "print('precision scores:', sgd_scor['test_precision_macro'])\n",
    "print('recall scores:', sgd_scor['test_recall_macro'])\n",
    "#print('Mean Accuracy: %.4f' % np.mean(sgd_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.nanmean(sgd_scor['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.nanmean(sgd_scor['test_recall_macro']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "precision scores: [       nan 0.46056911 0.46056911 0.46056911        nan]\n",
      "recall scores: [nan 0.5 0.5 0.5 nan]\n",
      "Mean Precision: 0.4606\n",
      "Mean Recall: 0.5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validation croisée sans SMOTE Tomek : 8.7s avec un échantillon divisé par 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "sgd_imb = Pipeline([('p', prep), ('r', resamplr), ('m', SGDClassifier())])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scoring = ['precision_macro','recall_macro'] #, 'accuracy']\n",
    "sgd_imb_scor = cross_validate(sgd_imb, X_train, y_train, scoring=scoring, cv=5)\n",
    "print('Model 1 - with imbalance handling\\n' + line_decor)\n",
    "#print('accuracy scores:', sgd_imb_scor['test_accuracy'])\n",
    "print('precision scores:', sgd_imb_scor['test_precision_macro'])\n",
    "print('recall scores:', sgd_imb_scor['test_recall_macro'])\n",
    "#print('Mean Accuracy: %.4f' % np.mean(sgd_imb_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.nanmean(sgd_imb_scor['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.nanmean(sgd_imb_scor['test_recall_macro']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1 - with imbalance handling\n",
      "--------\n",
      "precision scores: [       nan 0.55255999 0.5584412         nan 0.55571135]\n",
      "recall scores: [       nan 0.66237227 0.63354292        nan 0.67955739]\n",
      "Mean Precision: 0.5556\n",
      "Mean Recall: 0.6585\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validation croisée avec SMOTE Tomek (stratégie majoritaire) : 207.6s avec un échantillon divisé par 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "smote_unsmote_ratio = 207.6 / 8.7\n",
    "print('{:.2f}'.format(smote_unsmote_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.86\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "smote_unsmote_ratio = 186.5 / 9.6\n",
    "print('{:2f}'.format(smote_unsmote_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19.427083\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le SMOTE Tomek multiplie par un facteur 19 à 24 le temps d'exécution du modèle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Essai d'une validation croisée sans SMOTE Tomek avec tous les points du jeu d'entraînement"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train: (246008, 120)\n",
      "y_train: (246008, 1)\n",
      "X_test: (61503, 120)\n",
      "y_test: (61503, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "sgd = Pipeline([('p', prep), ('m', SGDClassifier())])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scoring = ['precision_macro','recall_macro'] #, 'accuracy']\n",
    "sgd_scor = cross_validate(sgd, X_train, y_train, scoring=scoring, cv=cv)\n",
    "print('Model 1\\n' + line_decor)\n",
    "#print('accuracy scores:', sgd_scor['test_accuracy'])\n",
    "print('precision scores:', sgd_scor['test_precision_macro'])\n",
    "print('recall scores:', sgd_scor['test_recall_macro'])\n",
    "#print('Mean Accuracy: %.4f' % np.mean(sgd_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.nanmean(sgd_scor['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.nanmean(sgd_scor['test_recall_macro']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "precision scores: [0.45967644 0.45966627 0.45966627 0.45967562 0.45967562]\n",
      "recall scores: [0.5 0.5 0.5 0.5 0.5]\n",
      "Mean Precision: 0.4597\n",
      "Mean Recall: 0.5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Validation croisée sans SMOTE Tomek exécutée en 57.9s sur tout le jeu de données"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "unsampled_sampled_ratio = 57.9 / 8.7\n",
    "print('{:.2f}'.format(unsampled_sampled_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6.66\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il faut 7 fois plus de temps pour exécuter la même chose sur 10 fois plus de données (pas parfaitement linéaire donc)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print('{:.2f}'.format(207.6 * unsampled_sampled_ratio))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1381.61\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "1381 / 60"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23.016666666666666"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il faudrait 23 minutes rien que pour faire du rééquilibrage avec le jeu de données actuel. Pas souhaitable. \n",
    "\n",
    "**Il faut trouver un moyen de raccourcir le temps d'exécution du rééquilibrage.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Réduction du temps de rééquilibrage en suppprimant des colonnes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "X_train_resampl_cut, y_train_resampl_cut = resamplr.fit_resample(\n",
    "    X_train_trans[:,:50], y_train\n",
    "    )\n",
    "print(X_train_resampl_cut.shape)\n",
    "print(y_train_resampl_cut.value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45313, 50)\n",
      "1    22659\n",
      "0    22654\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "temps d'entraînement 52s pour un jeu d'entraînement divisé par 10 avec seulement les 50 premières colonnes contre 60.5s avec toutes les colonnes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sous-échantillonage aléatoire"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train: (246008, 120)\n",
      "y_train: (246008,)\n",
      "X_test: (61503, 120)\n",
      "y_test: (61503,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "sgd_imb = Pipeline([('p', prep), ('r', rusamplr), ('m', SGDClassifier())])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scoring = ['precision_macro','recall_macro'] #, 'accuracy']\n",
    "sgd_imb_scor = cross_validate(sgd_imb, X_train, y_train, scoring=scoring, cv=5)\n",
    "print('Model 1 - with imbalance handling\\n' + line_decor)\n",
    "#print('accuracy scores:', sgd_imb_scor['test_accuracy'])\n",
    "print('precision scores:', sgd_imb_scor['test_precision_macro'])\n",
    "print('recall scores:', sgd_imb_scor['test_recall_macro'])\n",
    "#print('Mean Accuracy: %.4f' % np.mean(sgd_imb_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.nanmean(sgd_imb_scor['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.nanmean(sgd_imb_scor['test_recall_macro']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1 - with imbalance handling\n",
      "--------\n",
      "precision scores: [0.54163367        nan 0.56050468 0.55293874        nan]\n",
      "recall scores: [0.62721639        nan 0.67366715 0.67118886        nan]\n",
      "Mean Precision: 0.5517\n",
      "Mean Recall: 0.6574\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle 1 : SGD Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model1 = Pipeline([('p', prep), ('m', SGDClassifier())])\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('Model 1\\n' + line_decor)\n",
    "print('Score: %.4f' % model1.score(X_test, y_test))\n",
    "print(line_decor + '\\nConfusion matrix\\n' + str(conf_mat))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "Score: 0.9190\n",
      "--------\n",
      "Confusion matrix\n",
      "[[56522     0]\n",
      " [ 4981     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56522\n",
      "           1       0.00      0.00      0.00      4981\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.46      0.50      0.48     61503\n",
      "weighted avg       0.84      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle 2 : Random Forest Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model2 = Pipeline([('p', prep_no_scl), ('m', RandomForestClassifier())])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scoring = ['accuracy','precision_macro','recall_macro']\n",
    "scores_model2 = cross_validate(model2, X_train, y_train, scoring=scoring, cv=cv,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "print('Model 2\\n' + 8 * '-')\n",
    "print('Mean Accuracy: %.4f' % np.mean(scores_model2['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.mean(scores_model2['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.mean(scores_model2['test_recall_macro']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model2 = Pipeline([('p', prep_no_scl), ('m', RandomForestClassifier())])\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('Model 2\\n' + 8 * '-')\n",
    "print('Score: %.4f' % model2.score(X_test, y_test))\n",
    "print(8 * '-' + '\\nConfusion matrix\\n' + str(conf_mat))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model 1\n",
      "--------\n",
      "Score: 0.9185\n",
      "--------\n",
      "Confusion matrix\n",
      "[[56485     4]\n",
      " [ 5011     3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56489\n",
      "           1       0.43      0.00      0.00      5014\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.67      0.50      0.48     61503\n",
      "weighted avg       0.88      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# undersmpling \n",
    "# foret d'arbre -> feature importance\n",
    "# lightgbm\n",
    "# si besoin pca ou autre\n",
    "\n",
    "# optimisation du threshold\n",
    "# flask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[56512     5]\n",
      " [ 4979     7]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.get_params()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle 3 : LightGBM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model3 = Pipeline([('p', prep), ('m', LGBMClassifier())])\n",
    "model3.fit(X_train, y_train)\n",
    "print('Score:', model3.score(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score: 0.9192071931450498\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[56447    81]\n",
      " [ 4888    87]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56528\n",
      "           1       0.52      0.02      0.03      4975\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.72      0.51      0.50     61503\n",
      "weighted avg       0.89      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# à faire\n",
    "\n",
    "# smote tomek\n",
    "# random search precision des deux classes (privilégier light_gbm)\n",
    "# \n",
    "# choisir optimisation recall(classe 1)\n",
    "# fonction coût : manque à gagner pour chaque treshold\n",
    "# treshold = + = + precision - recall\n",
    "# precision élevée = on accepte tout le monde\n",
    "# recall élevée = on refuse tout le monde\n",
    "# regarder crer une colonne intérêts (amt credit - good price),\n",
    "# optimiser mon threshold % de ça"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2021-09-30 : Modélisation avec sous-échantillonage aléatoire de la classe majoriaire"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Importations\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing import preprocessor as prep, pandas_special_prepro as pd_prep\n",
    "from preprocessing import preprocessor_no_scaler as prep_no_scl\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Initialisation\n",
    "train = pd.read_csv('../02_data/application_train.csv')\n",
    "#test = pd.read_csv('../02_data/application_test.csv')\n",
    "\n",
    "id_error_msg = lambda x: '`SK_ID_CURR` is not unic for {} set!'.format(x)\n",
    "assert len(train.SK_ID_CURR.unique()) == train.shape[0], id_error_msg('train')\n",
    "#assert len(test.SK_ID_CURR.unique()) == test.shape[0], id_error_msg('test')\n",
    "train.set_index('SK_ID_CURR', inplace=True)\n",
    "#test.set_index('SK_ID_CURR', inplace=True)\n",
    "\n",
    "print('Training set dimensions :', train.shape)\n",
    "df = train.copy()\n",
    "\n",
    "cls_size = df.TARGET.value_counts()\n",
    "cls_freq = df.TARGET.value_counts(normalize=True)\n",
    "print(pd.DataFrame({'size': cls_size,\n",
    "                    'freq': cls_freq.apply(lambda x: '%.3f' % x)}))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set dimensions : (307511, 121)\n",
      "     size   freq\n",
      "0  282686  0.919\n",
      "1   24825  0.081\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "full_prepro = Pipeline(steps=[\n",
    "    ('pd_prep', pd_prep),\n",
    "    ('sk_prep', prep)\n",
    "    ])\n",
    "\n",
    "rand_usampl = RandomUnderSampler()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "All intermediate steps of the chain should not be Pipelines",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16670/858011860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m full_prepro = Pipeline(steps=[\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'pd_prep'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'sk_prep'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/bin/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/bin/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/bin/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    152\u001b[0m                     \u001b[0;34m\"All intermediate steps of the chain should not be Pipelines\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 )\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps of the chain should not be Pipelines"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Essais avec un classifieur en arbre de décision"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "tree_imb = Pipeline(steps=[\n",
    "    ('r', rand_usampl),\n",
    "    ('p', full_prepro),\n",
    "    ('m', DecisionTreeClassifier())\n",
    "    ])"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e28ba1b0f05b7395975e75d076f4168a18cd6381404260e3ea0bab694b3a7839"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}